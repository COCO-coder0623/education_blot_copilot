/**
 * APIåŠŸèƒ½æµ‹è¯•è„šæœ¬
 * ç”¨äºŽéªŒè¯OpenAIå’Œå¾®è½¯OCR APIçš„åŠŸèƒ½çŠ¶æ€
 */

// æµ‹è¯•OpenAI API (æ–‡å­—æ¨¡å¼)
export const testOpenAITextMode = async () => {
  try {
    const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
    if (!apiKey || apiKey === 'your_openai_api_key_here') {
      return { success: false, error: 'OpenAI APIå¯†é’¥æœªé…ç½®' };
    }

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'gpt-4o',
        messages: [{
          role: 'user',
          content: 'è¯·å›žå¤"OpenAIæ–‡å­—æ¨¡å¼æ­£å¸¸"'
        }],
        max_tokens: 50
      })
    });

    if (!response.ok) {
      const error = await response.text();
      return { success: false, error: `APIè°ƒç”¨å¤±è´¥: ${response.status} - ${error}` };
    }

    const data = await response.json();
    const result = data.choices[0]?.message?.content || '';
    
    return { 
      success: true, 
      result, 
      hasVisionCapability: false // ä»…æµ‹è¯•æ–‡å­—æ¨¡å¼
    };

  } catch (error) {
    return { 
      success: false, 
      error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯' 
    };
  }
};

// æµ‹è¯•OpenAI API (è§†è§‰æ¨¡å¼)
export const testOpenAIVisionMode = async () => {
  try {
    const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
    if (!apiKey || apiKey === 'your_openai_api_key_here') {
      return { success: false, error: 'OpenAI APIå¯†é’¥æœªé…ç½®' };
    }

    // åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾åƒ (1x1åƒç´ çš„ç™½è‰²PNG)
    const testImageBase64 = 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg==';
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'gpt-4o',
        messages: [{
          role: 'user',
          content: [
            {
              type: 'text',
              text: 'è¯·åˆ†æžè¿™å¼ å›¾ç‰‡å¹¶å›žå¤"OpenAIè§†è§‰æ¨¡å¼æ­£å¸¸"'
            },
            {
              type: 'image_url',
              image_url: {
                url: `data:image/png;base64,${testImageBase64}`,
                detail: 'low'
              }
            }
          ]
        }],
        max_tokens: 50
      })
    });

    if (!response.ok) {
      const error = await response.text();
      return { success: false, error: `è§†è§‰APIè°ƒç”¨å¤±è´¥: ${response.status} - ${error}` };
    }

    const data = await response.json();
    const result = data.choices[0]?.message?.content || '';
    
    // æ£€æŸ¥æ˜¯å¦è¿”å›žäº†æ‹’ç»è§†è§‰åŠŸèƒ½çš„æ¶ˆæ¯
    if (result.includes("unable to process images") || 
        result.includes("cannot analyze images") ||
        result.includes("I can't see")) {
      return { 
        success: false, 
        error: 'è´¦æˆ·æ²¡æœ‰GPT-4oè§†è§‰åŠŸèƒ½æƒé™',
        hasVisionCapability: false
      };
    }
    
    return { 
      success: true, 
      result, 
      hasVisionCapability: true
    };

  } catch (error) {
    return { 
      success: false, 
      error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯' 
    };
  }
};

// æµ‹è¯•å¾®è½¯OCR API
export const testMicrosoftOCR = async () => {
  try {
    const endpoint = import.meta.env.VITE_AZURE_VISION_ENDPOINT;
    const apiKey = import.meta.env.VITE_AZURE_VISION_KEY;
    
    if (!endpoint || !apiKey) {
      return { success: false, error: 'å¾®è½¯OCR APIæœªé…ç½®' };
    }

    // ç®€å•çš„è¿žæŽ¥æµ‹è¯•
    const response = await fetch(`${endpoint}/vision/v3.2/read/analyze`, {
      method: 'POST',
      headers: {
        'Ocp-Apim-Subscription-Key': apiKey,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        url: 'https://via.placeholder.com/150x50/000000/FFFFFF?text=TEST'
      })
    });

    if (response.status === 401) {
      return { success: false, error: 'OCR APIå¯†é’¥æ— æ•ˆ' };
    }
    
    if (response.status === 403) {
      return { success: false, error: 'OCR APIè®¿é—®è¢«æ‹’ç»' };
    }

    // 202æ˜¯æ­£å¸¸çš„æäº¤å“åº”
    if (response.status === 202) {
      return { success: true, result: 'OCR APIè¿žæŽ¥æ­£å¸¸' };
    }

    return { 
      success: false, 
      error: `OCR APIå“åº”å¼‚å¸¸: ${response.status}` 
    };

  } catch (error) {
    return { 
      success: false, 
      error: error instanceof Error ? error.message : 'ç½‘ç»œè¿žæŽ¥å¤±è´¥' 
    };
  }
};

// ç»¼åˆAPIçŠ¶æ€æ£€æµ‹
export const checkAPIStatus = async () => {
  console.log('ðŸ” å¼€å§‹æ£€æµ‹APIçŠ¶æ€...');
  
  const results = {
    openaiText: await testOpenAITextMode(),
    openaiVision: await testOpenAIVisionMode(),
    microsoftOCR: await testMicrosoftOCR()
  };

  // ç”Ÿæˆå»ºè®®
  const recommendations: string[] = [];
  
  if (!results.openaiText.success) {
    recommendations.push('ðŸ”‘ é…ç½®OpenAI APIå¯†é’¥');
  }
  
  if (!results.openaiVision.success) {
    if (results.openaiText.success) {
      recommendations.push('ðŸ’¡ OpenAIè´¦æˆ·æ— è§†è§‰åŠŸèƒ½ï¼Œå»ºè®®ä½¿ç”¨OCR+æ–‡å­—æ¨¡å¼');
    } else {
      recommendations.push('ðŸ” æ£€æŸ¥OpenAIè´¦æˆ·æƒé™å’Œä½™é¢');
    }
  }
  
  if (!results.microsoftOCR.success) {
    recommendations.push('ðŸ–¼ï¸ é…ç½®å¾®è½¯Azure Computer Vision APIä½œä¸ºOCRå¤‡ç”¨æ–¹æ¡ˆ');
  }

  // ç¡®å®šæŽ¨èçš„ä½¿ç”¨æ¨¡å¼
  let recommendedMode = '';
  if (results.openaiVision.success) {
    recommendedMode = 'ðŸŽ¯ æŽ¨èä½¿ç”¨ï¼šå›¾åƒç›´æŽ¥è¯†åˆ«æ¨¡å¼';
  } else if (results.openaiText.success && results.microsoftOCR.success) {
    recommendedMode = 'ðŸŽ¯ æŽ¨èä½¿ç”¨ï¼šOCR + æ–‡å­—æ‰¹æ”¹æ¨¡å¼';
  } else if (results.openaiText.success) {
    recommendedMode = 'âš ï¸ ä»…æ–‡å­—æ¨¡å¼å¯ç”¨ï¼Œéœ€è¦æ‰‹åŠ¨è¾“å…¥é¢˜ç›®å†…å®¹';
  } else {
    recommendedMode = 'âŒ éœ€è¦é…ç½®APIæ‰èƒ½ä½¿ç”¨æ‰¹æ”¹åŠŸèƒ½';
  }

  console.log('ðŸ“Š APIçŠ¶æ€æ£€æµ‹ç»“æžœ:', {
    OpenAIæ–‡å­—æ¨¡å¼: results.openaiText.success ? 'âœ…' : 'âŒ',
    OpenAIè§†è§‰æ¨¡å¼: results.openaiVision.success ? 'âœ…' : 'âŒ',
    å¾®è½¯OCR: results.microsoftOCR.success ? 'âœ…' : 'âŒ',
    æŽ¨èæ¨¡å¼: recommendedMode
  });

  return {
    results,
    recommendations,
    recommendedMode,
    summary: {
      hasTextMode: results.openaiText.success,
      hasVisionMode: results.openaiVision.success,
      hasOCR: results.microsoftOCR.success,
      canUseDirect: results.openaiVision.success,
      canUseOCR: results.openaiText.success && results.microsoftOCR.success,
      needsConfiguration: !results.openaiText.success
    }
  };
};

// åœ¨æŽ§åˆ¶å°ä¸­è¿è¡Œæµ‹è¯•çš„ä¾¿æ·å‡½æ•°
export const runQuickTest = async () => {
  const status = await checkAPIStatus();
  
  console.log('\nðŸŽ¯ å¿«é€Ÿé…ç½®å»ºè®®:');
  status.recommendations.forEach(rec => console.log(rec));
  
  console.log('\n' + status.recommendedMode);
  
  return status;
};
